{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pipeline\n",
    "\n",
    "Pipeline is a Python package\n",
    "that adds a customizable caching capabilities to [dask](https://dask.org).\n",
    "It builds on top of `dask.delayed`,\n",
    "adding load and save instructions\n",
    "to the dask graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import Storage, task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The task decorator\n",
    "\n",
    "A task can be created from a function using `task` as a decorator.\n",
    "\n",
    "If you're familiar with `dask.delayed`,\n",
    "`task` uses `dask.delayed(pure=True)` inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def double(x: float) -> float:\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the function doesn't perform the computation immediately,\n",
    "but returns a `dask.delayed` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('double/54abf7066a03bddb650fbb1616e27bc5')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the result,\n",
    "you must call the `.compute` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double(21).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing results to disk\n",
    "\n",
    "So far,\n",
    "a task behaves as a `dask.delayed`.\n",
    "But,\n",
    "additionally,\n",
    "we can easily save and load data\n",
    "to avoid recomputing expensive tasks,\n",
    "even between different Python sessions.\n",
    "\n",
    "To do that,\n",
    "we first need to create a `Storage` object,\n",
    "which accepts any object implementing a `MutableMapping[str, bytes]` interface.\n",
    "It also accepts a `str`,\n",
    "which is passed to `fsspec` to create an `fsspec.FSMap`.\n",
    "\n",
    "Here,\n",
    "we will just use a simply Python `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = Storage({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save (and then load) a task,\n",
    "we must explicitly create it with `save=True`,\n",
    "as we probably don't want to save cheap to compute\n",
    "and expensive to store tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(save=True)\n",
    "def double_with_print(x: float) -> float:\n",
    "    out = 2 * x\n",
    "    # The next line is just to demonstrate\n",
    "    # that the function does not run\n",
    "    # when it is loaded from the Storage\n",
    "    print(f\"Calculating: 2 * {x} = {out}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again,\n",
    "calling the function does not actually run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('double_with_print/54abf7066a03bddb650fbb1616e27bc5')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_task = double_with_print(21)\n",
    "\n",
    "my_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but creates a `dask.delayed` object.\n",
    "\n",
    "If we call `.compute()`,\n",
    "we see the `print` statement inside the function\n",
    "and it returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating: 2 * 21 = 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_task.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,\n",
    "if we call compute inside an storage context manager,\n",
    "that result will be saved to the storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating: 2 * 21 = 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with storage():\n",
    "    result = my_task.compute()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect `fs` attribute of the storage,\n",
    "which in this case corresponds to a `dict`,\n",
    "and see that the result was saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'double_with_print/54abf7066a03bddb650fbb1616e27bc5': b'(\\xb5/\\xfd \\x05)\\x00\\x00\\x80\\x05K*.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we recompute the task inside the context manager,\n",
    "we obtain the same result,\n",
    "but we see no output from the `print` function,\n",
    "as `double_with_print` wasn't actually run,\n",
    "but the result retrieved from storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with storage():\n",
    "    result = my_task.compute()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recomputing outside the context manager does run the function again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating: 2 * 21 = 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_task.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:**\n",
    "functions are expected to be **pure**,\n",
    "that is,\n",
    "that their output only depend on their input parameters,\n",
    "and have no side effects.\n",
    "\n",
    "A function will not be called again\n",
    "when its output is already stored.\n",
    "\n",
    "Example of non-pure functions:\n",
    "\n",
    "- **Mutating input**: using in-place operations.\n",
    "- **Non-deterministic output**: drawing random numbers, or relying on global variables.\n",
    "- **Side effects:** updating global variables.\n",
    "\n",
    "We've seen an example of a side effect:\n",
    "the `print` function in the previous example\n",
    "was not called when recomputing the task\n",
    "(inside the storage context manager)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom encoding\n",
    "\n",
    "To store data,\n",
    "results need to be encoded into a bytes representation.\n",
    "By default,\n",
    "`task` encodes data by\n",
    "serializing with `cloudpickle` and\n",
    "compressing with `zstandard`.\n",
    "\n",
    "But,\n",
    "`cloudpickle` is not appropriate for long-term storage,\n",
    "as it depends on the Python version used.\n",
    "\n",
    "To customize the encoding,\n",
    "`task` accepts any encoder implementing the `Encoder[T, bytes]` protocol:\n",
    "\n",
    "```python\n",
    "class Encoder(Protocol[T, E]):\n",
    "    def encode(self, value: T) -> E: ...\n",
    "    def decode(self, value: E) -> T: ...\n",
    "```\n",
    "\n",
    "We offer a customizable `DefaultEncoder`,\n",
    "which accepts the following arguments:\n",
    "\n",
    "```python\n",
    "@dataclass(kw_only=True)\n",
    "class DefaultEncoder:\n",
    "    encoders: tuple[Encoder] = ()\n",
    "    serializer: Serializer | None = cloudpickle\n",
    "    compressor: Compressor | None = zstandard\n",
    "    encrypter: Encrypter | None = None\n",
    "```\n",
    "\n",
    "where\n",
    "\n",
    "| type       | implements           |\n",
    "|------------|----------------------|\n",
    "| Encoder    | encode, decode       |\n",
    "| Serializer | dumps, loads         |\n",
    "| Compressor | compress, decompress |\n",
    "| Encrypter  | encrypt, decrypt     |\n",
    "\n",
    "The `DefaultEncoder` applies the following transformations:\n",
    "\n",
    "`encoders[0] -> ... -> encoder[-1] > serializer -> compressor -> encrypter`\n",
    "\n",
    "when encoding,\n",
    "and in reverse order when decoding.\n",
    "\n",
    "Most serializers, compressors and encrypters already implement these interfaces,\n",
    "so you can simply import a module/class/object and pass it to `DefaultEncoder()`.\n",
    "\n",
    "For instance,\n",
    "[`numcodecs`](https://numcodecs.readthedocs.io/en/stable/)\n",
    "implements several encoders\n",
    "that might be useful to apply before serializing.\n",
    "\n",
    "In the submodule `serializer`,\n",
    "some commonly used serializers are already included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import DefaultEncoder, serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following function,\n",
    "we will create 3 task variants,\n",
    "with different serializers,\n",
    "and no compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set compressor=None to leave an human-readable byte representation\n",
    "def point_as_dict(x, y):\n",
    "    return dict(x=x, y=y)\n",
    "\n",
    "\n",
    "@task(save=True, encoder=DefaultEncoder(compressor=None))\n",
    "def point_as_cloudpickle(x, y):\n",
    "    return point_as_dict(x, y)\n",
    "\n",
    "\n",
    "@task(save=True, encoder=DefaultEncoder(serializer=serializer.json, compressor=None))\n",
    "def point_as_json(x, y):\n",
    "    return point_as_dict(x, y)\n",
    "\n",
    "\n",
    "@task(save=True, encoder=DefaultEncoder(serializer=serializer.yaml, compressor=None))\n",
    "def point_as_yaml(x, y):\n",
    "    return point_as_dict(x, y)\n",
    "\n",
    "\n",
    "with storage():\n",
    "    point_as_cloudpickle(x=1, y=2).compute()\n",
    "    point_as_json(x=1, y=2).compute()\n",
    "    point_as_yaml(x=1, y=2).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect the storage,\n",
    "we can read see the different outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'double_with_print/54abf7066a03bddb650fbb1616e27bc5': b'(\\xb5/\\xfd \\x05)\\x00\\x00\\x80\\x05K*.',\n",
       " 'point_as_cloudpickle/b6e4f13ef66a0d1496c9561971b0b66c': b'\\x80\\x05\\x95\\x11\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x94(\\x8c\\x01x\\x94K\\x01\\x8c\\x01y\\x94K\\x02u.',\n",
       " 'point_as_json/b6e4f13ef66a0d1496c9561971b0b66c': b'{\"x\": 1, \"y\": 2}',\n",
       " 'point_as_yaml/b6e4f13ef66a0d1496c9561971b0b66c': b'x: 1\\ny: 2\\n'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom output naming\n",
    "\n",
    "By default,\n",
    "an output's name is given by `f\"{task.name}{arguments_hash}\"`.\n",
    "\n",
    "The `task` decorator accepts a `name` argument\n",
    "to customize its name,\n",
    "either by passing an `str`,\n",
    "or a callable which receives the underlying function `func`.\n",
    "By default,\n",
    "it uses a callable which returns `func.__name__ + \"/\"`.\n",
    "\n",
    "The hash of the arguments can also be customized,\n",
    "passing a function to the `hasher` parameter of `task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('double-21')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_function_namer(func: callable) -> str:\n",
    "    return f\"{func.__name__}-\"\n",
    "\n",
    "\n",
    "def my_hasher(args: tuple, kwargs: dict) -> str:\n",
    "    return str(args[0])\n",
    "\n",
    "\n",
    "@task(name=my_function_namer, hasher=my_hasher)\n",
    "def double(x):\n",
    "    return 2 * x\n",
    "\n",
    "\n",
    "double(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Storages\n",
    "\n",
    "There are two ways to combine storages:\n",
    "\n",
    "#### Chaining storages\n",
    "\n",
    "To join multiple storages,\n",
    "we can use `Storage.chain`\n",
    "to create a joint `MutableMapping`:\n",
    "\n",
    "```python\n",
    "storage_local = Storage(\"/local_folder\")\n",
    "storage_remote = Storage(\"ssh://user@server/home/user/remote_folder\")\n",
    "storage_combined = Storage.from_chain(storage_local, storage_remote)\n",
    "\n",
    "with storage_combined():\n",
    "    ...\n",
    "```\n",
    "\n",
    "In this case,\n",
    "`storage` will try to load in order,\n",
    "first from `\"local_folder\"`\n",
    "and then from `\"remote_folder\"`.\n",
    "If it needs to save a task,\n",
    "it will be saved to the first one (`local_storage`).\n",
    "\n",
    "*Note: underneath it's just using a `collections.ChainMap` to join them.*\n",
    "\n",
    "#### Nested storages\n",
    "\n",
    "Alternatively, we can simply nest the context managers:\n",
    "\n",
    "```python\n",
    "with storage_remote():\n",
    "    # Tasks computed here load from and save to remote only\n",
    "    task.compute()\n",
    "\n",
    "    with storage_local():\n",
    "        # Tasks computed here load from local or remote (in that order)\n",
    "        # and save to local.\n",
    "        task.compute()\n",
    "\n",
    "    with storage_local(nested=False):\n",
    "        # Tasks computed here ignore remote\n",
    "        task.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read more at dask.org\n",
    "\n",
    "As `Task` works on top of `dask.delayed`,\n",
    "it is useful to check out dask's documentation:\n",
    "\n",
    "- Delayed: https://docs.dask.org/en/stable/delayed.html\n",
    "- Delayed Collections: https://docs.dask.org/en/stable/delayed-collections.html\n",
    "- Delayed Best Practices: https://docs.dask.org/en/stable/delayed-best-practices.html\n",
    "- General Best Practices: https://docs.dask.org/en/stable/best-practices.html\n",
    "\n",
    "Many tips discussed there apply for `Task` too.\n",
    "In particular,\n",
    "these points,\n",
    "which were discussed before:\n",
    "\n",
    "- Don’t mutate inputs\n",
    "- Avoid global state\n",
    "- Don’t rely on side effects"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53db425adbeb5274c539f12630014ccb52619270733afeaf3d2657c734123dfc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('pipeline': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
